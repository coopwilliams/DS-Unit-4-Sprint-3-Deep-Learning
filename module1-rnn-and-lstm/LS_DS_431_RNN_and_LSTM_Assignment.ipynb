{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bV0DXNfpZKcb"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "Ltj1je1fp5rO",
    "outputId": "4882ffd1-1a2d-411f-c6db-02b48cbb246e"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart.\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "maxlen = 80\n",
    "max_features = 20000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "uvl28RhjZKcl",
    "outputId": "c62ce9a0-fb94-4511-b0a7-efd69aaf7db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9896\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "data = urllib.request.urlopen(url).read(10000).decode('utf-8')\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEsphEQpZKcq"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get(url)\n",
    "data.encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "ZouzxzKgZKcu",
    "outputId": "24d0a1c1-6ef8-4149-9e70-99434464f1e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff\\r\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\r\\nShakespeare\\r\\n\\r\\nThis eBook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever.  You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this eBook or online at\\r\\nwww.gutenberg.org.  If you are not located in the United States, you’ll\\r\\nhave to check the laws of the country where '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IOOJuE0vWQj"
   },
   "outputs": [],
   "source": [
    "text = data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYWXm7lKu-lb"
   },
   "outputs": [],
   "source": [
    "# encode the data as characters\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "09qzkp5Dvjz-",
    "outputId": "e2113b8c-d1d0-4dc7-f5a7-9b261a65651e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff\\r\\nProject Gutenberg’s The Complete Works of Willi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "7_vrkjtJv2YY",
    "outputId": "688cb945-c6b6-4005-a2c4-02bdd0149412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 1913338\n"
     ]
    }
   ],
   "source": [
    "maxlen=40\n",
    "step=3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "qrG1XgzCwUkm",
    "outputId": "ba520dfe-5f70-4fc3-b256-66bea7033862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stE6snc7wkty"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYVatEYFxg00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913338, 40, 108)\n",
      "(1913338, 108)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUcqrW7wxi6N"
   },
   "outputs": [],
   "source": [
    "# Build the LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metric='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1913338 samples\n",
      "Epoch 1/5\n",
      "1912448/1913338 [============================>.] - ETA: 0s - loss: 1.6566\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"would give; but you well know\n",
      "    Thing\"\n",
      "would give; but you well know\n",
      "    Thing the stard of the stance of the stand,\n",
      "    The father to the stranger of the stranger of the stranger of the stand.\n",
      "\n",
      "                                                                                                                                                                                                                                                                                        \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"would give; but you well know\n",
      "    Thing\"\n",
      "would give; but you well know\n",
      "    Thing of me to the essitions.\n",
      "                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"would give; but you well know\n",
      "    Thing\"\n",
      "would give; but you well know\n",
      "    Things are beyon that I am my mind call at sins.\n",
      "    When I know me beloig-pllast’s cright;\n",
      "    Shell by the day supsin or tend us by on reGoltt, and patity\n",
      "With canr'd to a sseon.\n",
      "\n",
      "post the stemwer of.                                                                                                Resenter and , the slame.\n",
      "  YORK. His lord.\n",
      "\n",
      "CENTIO.\n",
      "My confolk fore.\n",
      "    I know thou as ready.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"would give; but you well know\n",
      "    Thing\"\n",
      "would give; but you well know\n",
      "    Thing killable.\n",
      "\n",
      "HITHERVIOUS.\n",
      "It listoy,\n",
      "\n",
      "HAMPEEHANTESTORg.\n",
      "Whereoo; you, and howly wott; By this that'st a sAm thatof;\n",
      "This morensrouge, he, but, if thou all my mughfyforspo-comrervergarty\n",
      "    Tobmokt furnily.\n",
      "\n",
      "PAROLIO.\n",
      "Shall\n",
      "Hown lo, donam messits amitaouset cap to day:\n",
      "row you from anink enmament!\n",
      "  IGON L Rey enepbuirses._]\n",
      "\n",
      "accour of no\n",
      "both past lile then slievt or crusia. That, \n",
      "1913338/1913338 [==============================] - 138s 72us/sample - loss: 1.6566\n",
      "Epoch 2/5\n",
      "1912192/1913338 [============================>.] - ETA: 0s - loss: 1.5220\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"all; I dare not call. Yet famine,\n",
      "Ere c\"\n",
      "all; I dare not call. Yet famine,\n",
      "Ere come to the bear the fortunes to the strange to the father\n",
      "    That he shall be the sill the son and the strange.\n",
      "    What shall I shall some a man to my love to the son,\n",
      "    That I have so shall be the true the fortunes\n",
      "    Which the sight of the son to the profess the bear the heart.\n",
      "                                                                                                             \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"all; I dare not call. Yet famine,\n",
      "Ere c\"\n",
      "all; I dare not call. Yet famine,\n",
      "Ere cannot be the bear here; then he is my lord.\n",
      "    For your lose all her earth to be our did with the thurl\n",
      "    And with the made to bear the shame stand,\n",
      "    Bear the made to the day than that seem you.\n",
      "    I say she first be be not so brance of me\n",
      "    And be no your princes the prince both\n",
      "                                                                                                        \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"all; I dare not call. Yet famine,\n",
      "Ere c\"\n",
      "all; I dare not call. Yet famine,\n",
      "Ere cutity arroinst, but a house thou shally\n",
      "    very pirdolury cround with your tolgs,\n",
      "Why will you entirtaed to dont from true boy'st,\n",
      "    Till welpy too btest stanry all. Come intent\n",
      "accont beat into durse, in tenty.\n",
      "  ALM SRALIUS. My whole many cines’d on a good's wom\n",
      "resolcel’d I say moths is scarkly thatty.\n",
      "\n",
      "IAGO. Chirds on all no: no, learn!                                               \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"all; I dare not call. Yet famine,\n",
      "Ere c\"\n",
      "all; I dare not call. Yet famine,\n",
      "Ere cle't that shellilsantion. Sir three bittafnce;\n",
      "When no low hrough and heir.\n",
      "\n",
      "SECOND HELs\n",
      "yon't each.\n",
      "  But that faverinf.\n",
      "\n",
      "STEPHANO]\n",
      "  nowepy, saveddowection,\n",
      "and avorse, if Deher, tageation in lo?\n",
      "      year not,\n",
      "These woep'd bir for visking to say.\n",
      "Our hair, with eiry! he righy even of swreece.\n",
      "    And co.enow thee, goodberturning Nursed\n",
      "I'll eam knowly doth be forch'st wrusters,\n",
      " \n",
      "1913338/1913338 [==============================] - 134s 70us/sample - loss: 1.5220\n",
      "Epoch 3/5\n",
      "1912832/1913338 [============================>.] - ETA: 0s - loss: 1.5045\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"hy pains;\n",
      "Farewell; commend me to thy m\"\n",
      "hy pains;\n",
      "Farewell; commend me to thy meatus the thing so some and the sorrow.\n",
      "    The shame to the state to the man of the wind the state heaven.\n",
      "    The thing the more than the shame the some son,\n",
      "    The state that she will the starder the fair father,\n",
      "    The some soul the shame the strange that I will be the stard\n",
      "    The worth and the stand than the stand and the with the speech\n",
      "    That the same the story so speaks the sta\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hy pains;\n",
      "Farewell; commend me to thy m\"\n",
      "hy pains;\n",
      "Farewell; commend me to thy mind mark us like the\n",
      "                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"hy pains;\n",
      "Farewell; commend me to thy m\"\n",
      "hy pains;\n",
      "Farewell; commend me to thy meat of slave,\n",
      "    And apprikation those purposutome, not tebtance\n",
      "                             Exit\n",
      "\n",
      "       ; she will I she years,\n",
      "wine one proviston, stale to take the come.\n",
      "\n",
      "                                                                Enter Poar twer. it GI?\n",
      "\n",
      "ALLIAD.\n",
      "Bread youte, then, I'll pays a mou made the very prevain’d neWaties, for sesters; thus feers of mere still\n",
      "    We l\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"hy pains;\n",
      "Farewell; commend me to thy m\"\n",
      "hy pains;\n",
      "Farewell; commend me to thy murcheilly. Understaint all cunnous;\n",
      "    And contengent the breed obonatine's most wish, will with lake.\n",
      "Neutherwmap to not mos that must be siptied-tod-hat\n",
      "To pins-a horse theyh’d of dies thilve; such hasacie a\n",
      "bidash'de blotd;\n",
      "very Bood Can marries he liwweres.\n",
      "\n",
      "\n",
      "      IAdiCHARLELE.\n",
      "      bots thply prinerys every Steyghs up\n",
      "Stuce a mis.—No how with mores, to crave quarece it\n",
      "must py r\n",
      "1913338/1913338 [==============================] - 131s 69us/sample - loss: 1.5044\n",
      "Epoch 4/5\n",
      "1913088/1913338 [============================>.] - ETA: 0s - loss: 1.5146\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e to do? ’Tis too late to pare her nails\"\n",
      "e to do? ’Tis too late to pare her nails and the the shall be the streghe the best sun of the shall not be be the strange the shall be the streghe the that than the hand that shall be some sun sound my love,\n",
      "    That the strange the bed the streghe that shall be the shall not stopted the heart,\n",
      "                                                                                                                                              \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e to do? ’Tis too late to pare her nails\"\n",
      "e to do? ’Tis too late to pare her nails,\n",
      "    Think the son, you condell her brother shall with the ere the hand with my sward,\n",
      "    Which he shall do I\n",
      "                                                      Exeunt Benatian.\n",
      "  CANDAR. Why, the was the fear for the proud soul the partic thee of the states.\n",
      "\n",
      "SECOND GENTLEMAN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See he give the time of Cassies the partic the the green than man to the heart to the servied. The counterer \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e to do? ’Tis too late to pare her nails\"\n",
      "e to do? ’Tis too late to pare her nails as art thoud, But set,\n",
      "Destin letter Gime, liw. Sow, bloodiers predus has the gard outstines me -count the, a a niebubleclaut.\n",
      "q BCINGE PAPMBTROLUS. With you swear you; and Sir in ho, good aspeeuin it letmen them forth. Would to the femio.\n",
      "peremon\n",
      "To agested thamin,\n",
      "Ao to kill,\n",
      "  oncrander van mindage.\n",
      "\n",
      "\n",
      "      whils, full of a calme and ganngd my decany.\n",
      "\n",
      "esbe the indily man man\n",
      "   \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e to do? ’Tis too late to pare her nails\"\n",
      "e to do? ’Tis too late to pare her nails,\n",
      "Pishear Mashin, our deeply and lovely accun Ca\n",
      ". Naole some shall go Prodion upoun youldly\n",
      "\n",
      "      Fairive heall, come one. for which bour\n",
      "To Helf; And blim! wise coat to peaction,\n",
      "    We cenphreades bring Flusling forth,\n",
      "Is in Godver faourd losvies, a crusning circum’d.\n",
      "\n",
      " Frencomedneus, morester. It life from ilam to nain Ca a. I ike him the ey, your fatber\n",
      "Than on my with your while w\n",
      "1913338/1913338 [==============================] - 136s 71us/sample - loss: 1.5147\n",
      "Epoch 5/5\n",
      "1912576/1913338 [============================>.] - ETA: 0s - loss: 1.5350\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" poorest,\n",
      "    Of this most wise rebelli\"\n",
      " poorest,\n",
      "    Of this most wise rebelling that he is the strangers.\n",
      "    The strange that he shall not see the son\n",
      "    The worship the stranger that have the land,\n",
      "    The state and the day and the strange of the son and the part of the state of the man that the strange of the state that he will not a part of the strains and the strains and the father,\n",
      "    The said that we shall be the part of the season to the part.\n",
      "    The said s\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" poorest,\n",
      "    Of this most wise rebelli\"\n",
      " poorest,\n",
      "    Of this most wise rebelling the more to fantious part to the pester the day to this faith?\n",
      "    In the stree which this ware mare of the fair\n",
      "    And the state will shall be betters, singland\n",
      "    And the little staff o"
     ]
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "         epochs=5,\n",
    "         callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
